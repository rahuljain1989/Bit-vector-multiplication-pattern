In this section, we present some basics of the theory of
quantifier-free fixed-width bit-vector formulas (\qfbv), and discuss
two well-known multiplication algorithms of interest.

%

\subsection{\qfbv: A short introduction}

A bit-vector is a fixed sequence of bits.
%
We denote bit-vectors by $x$,$y$,$z$, etc., and often
%
refer to blocks of bits in a bit-vector.
%
For example, we may declare that a bit-vector $x$ is accessed in
blocks of width $w$.
%
Let $x_i$ denote the $i$th block of bits, with the block containing
the least significant bit (LSB) having index $1$.
%
% Similar notation is used for the vectors of any object.

A $\qfbv$~term $t$ and formula $F$ is constructed using
the following grammar
\begin{align*}
t ::= &~ t * t \mid t + t \mid x \mid n^w \mid t \concat t  ....\\
F ::= &~ t = t \mid t \bowtie t \mid \lnot F \mid F \lor F \mid F \land F \mid F \lxor F \mid ... 
\end{align*}
where $x$ is a bit-vector variable, $n^w$ is a binary constant
represented using $w$ bits, $\bowtie$ is a predicate in $\{\leq , <,
\geq, > \}$, and $\concat$ is a binary operator that concatenates
bit-vectors.
%
Note that we have only presented above parts of the grammar
that are relevant to our discussion.  For more details,
the reader is referred to~\cite{Kroeningbook,barrett}.
%
We assume that all variables and arithmetic operators are unsigned.
Following the SMT-LIB~\cite{SMTLIB} convention, we also assume that
arguments and results of an arithmetic operator have the same bit width.
%
Let $len(t)$ denote the bit width of a term $t$.
%
If $w \geq len(t)$,
let $zeroExt(t,w)$ be a shorthand for  $0^{w-len(t)}\concat t$.

If an operator $\op$ is commutative, when matching patterns, we will
not make a distinction between $a \op b$ and $b \op a$.
%
We use the notation ``$t == s$'' to denote that $t$ and $s$ are
syntactically identical.
%
Given bit-vector terms $x$, $y$, and $t$, suppose $w = max(len(x),len(y),
len(t))$.
%
We use ``$[x*y = t]$'' to denote term $x'*y'=t'$, where $x' =
zeroExt(x, w)$, $y' = zeroExt(y, w)$, and $t' = zeroExt(t, w)$.
%
Similarly, the notation $[x*y]$ is used to denote $x' * y'$, where $x'
= zeroExt(x, len(x)+len(y))$ and $y' = zeroExt(y, len(x) + len(y))$.

%% \subsection{SMT solvers for \qfbv}

%% SMT(satisfiability modulo theory)
%% solvers are specialized solvers that solve 
%% formulas of a given theory.
%
State-of-the-art SMT solvers for \qfbv~apply several simplification and
re-writing passes to decide the satisfiability of the input formula.
If these do not succeed in solving the problem, the solvers bit-blast
the formula, i.e., translate the bit-vector formula to an
equivalent propositional formula on the constituent bits of the
bit-vectors.  This reduces the bit-vector satisfiability problem to
one of propositional satisfiability (SAT).
%
The bit-blasted SAT problem is then solved using conflict driven clause
learning (CDCL)\cite{cdcl1,cdcl2} based SAT procedures.
%
Some of the leading SMT solvers today are $\zthree$\cite{zthree},
$\boolector$\cite{boolector}, and $\cvcfour$\cite{cvcfour}.

For our work, we assume access to a generic $\qfbv$~SMT solver, called
$\textsc{SMTSolver}$, with a standard interface.
%
We assume that this interface provides access to two functions: (i) $add(F)$, that adds a
formula $F$ to the context of the solver, and (ii) $checkSat()$,
that checks the satisfiability of the conjunction of all formulas
added to the context of the solver.  Note that such interfaces are commonly
available with state-of-the-art SMT solvers, viz. {\boolector},
{\cvcfour} and {\zthree}.

\subsection{Multipliers}

As discussed in Section~\ref{sec:intro}, there are several alternative multiplier implementa-
tions that are used in hardware embedded systems. Among the most popular such implementations are long multipliers, Booth multipliers and Wallace-tree
multipliers. In this work, we focus only on long multipliers and Wallace-tree
multipliers. The study of our heuristic for systems containing Booth multipliers
is deferred as part of future work. %Multiplication is an expensive operation to implement in hardware.
%
%There are several designs of multipliers for varying
%resource constraints.
%
%If one can have a large number of gates then Wallace tree
%multiplier can be used.
%
%Otherwise, one may decompose the multiplication task in
%small multiplications and combine the results appropriately.
%
%For example, long multiplier and Booth multiplier.
%
%Here, we will discuss long and Wallace tree multiplier.

\subsubsection{Long multiplier}\label{sec:long-mult}

Consider bit-vectors $x$ and $y$ that are partitioned into $k$ blocks of width $w$ bits each. Thus the total width of each bit-vector is $k \cdot w$. 
% \ashu{Rahul: suggest a rewrite.}
The long multiplier decomposes the multiplication of two $k \cdot w$-bit wide bit-vectors into $k^2$ multiplications of $w$-bit wide bit-vectors. The corresponding $k^2$ products, called {\em partial products}, are then added with appropriate left-shifts to obtain the final
result. 
%
%The partial products are summed with appropriate offsets to obtain
%the final result.
%
The following notation is typically used to illustrate
long multiplication.
%
\begin{center}
\begin{tabular}{c@{\quad}c@{\quad}c@{\quad}c@{\quad}c@{\quad}c@{\quad}c}
  &&& $x_{k}$ & ... & $x_1$&\\ 
  &&& $y_{k}$ & ... & $y_1$&$*$\\ \hline
  &&&$x_k*y_1$& ... & $x_1*y_1$&\\
  &&$\iddots$&$\vdots$& $\iddots$ && \\
  &$x_k*y_k$& ... &$x_1*y_k$&  & +&\\\hline
\end{tabular}  
\end{center}
Here, the $x_i*y_j$s are the partial products. The partial product $x_i*y_j$ is left shifted $(i+j-2) \cdot w$ bits before being added. In the above representation, all partial
products that are left-shifted by the same amount are aligned in a single column.
After the left shifts, all the partial results are added in some order. 
%
%In the above scheme all the partial products that have same offset are 
%aligned in single column.
%
%After the shifts, all the partial results are added in some order.
%
Note that the bit-width of each partial product is $2 \cdot w$.
%
Since the syntax of $\qfbv$ requires the bit-widths of arguments and result of the $*$ operator to be the same, we
denote the partial product $x_i * y_j$ as 
$(0^w \concat x_i)*(0^w \concat y_j)$ for our purposes. Note
further that the bits of the partial products in neighbouring columns (in the
above representation of long multiplication) overlap; hence the sums of the
various columns can not be simply concatenated. The long multiplication algorithm does not specify the order of the addition of the shifted partial products. Therefore, there are several possible designs for a given $k$ and $w$.

\begin{example}
  Consider bit-vectors $v_1,v_2,u_1$, and $u_2$, each of width 2.
  Let us apply long multiplication to calculate
  $v_2 \concat 0^2 \concat v_1$ and $u_2 \concat v_2 \concat u_1$.
  We obtain the following partial products.
\begin{center}
\begin{tabular}{c@{\quad}c@{\quad}c@{\quad}c@{\quad}c@{\quad}c@{\quad}c}
  &&& $v_2$ & $0^2$ & $v_1$&\\ 
  &&& $u_2$ & $v_2$ & $u_1$&$*$\\ \hline
  &&&$v_2*u_1$& $0^4$ & $v_1*u_1$&\\
  &&$v_2*v_2$&$0^4$& $v_1*v_2$ && \\
  &$v_2*u_2$& $0^4$ &$v_1*u_2$&  & +&\\\hline
\end{tabular}
\end{center}
Note that while adding the shifted partial products, if the non-zero bits of a
subset of shifted partial products do not overlap, then we can simply concatenate
them to obtain their sum. Finally, we can sum the concatenated vectors thus
obtained to calculate the overall product. The following is one of the combination
of the concatenations and summations for the long multiplication.
%
%And finally we may sum the concatenated vectors.
%
%The following is one of the combination of the concatenations and 
%summations for the long multiplication.
$$
( 0^4 \concat v_1*u_2 \concat v_1*u_1) +
(v_2*u_2 \concat v_2*u_1 \concat 0^4) +
(0^2 \concat v_2*v_2 \concat v_1*v_2 \concat 0^2)
$$
\end{example}


\begin{example}

  As another interesting example, consider long multiplication applied to 
  $v_2 \concat 0^2 \concat v_2$ and $0^2 \concat v_1 \concat v_1$.
  We obtain the following partial products.
\begin{center}
\begin{tabular}{c@{\quad}c@{\quad}c@{\quad}c@{\quad}c@{\quad}c@{\quad}c}
  &&& $v_2$ & $0^2$ & $v_2$&\\ 
  &&& $0^2$ & $v_1$ & $v_1$&$*$\\ \hline
  &&&$v_1*v_2$& $0^4$ & $v_1*v_2$&\\
  &&$v_1*v_2$&$0^4$& $v_1*v_2$ &+&\\\hline
  %&$v_2*u_2$& $0^4$ &$v_1*u_2$&  & +&\\\hline
\end{tabular}
\end{center}


Note that, if we had applied the long multiplication to $v_1 \concat
0^2 \concat v_1$ and $0^2 \concat v_2 \concat v_2$, we would have got
the same partial products. This shows that simply knowing the
collections of partial products at different indexes does not allow us
to uniquely determine the operands. Recall that this problem was
alluded to in Section~\ref{sec:intro}.

\end{example}


\subsubsection{Wallace tree multiplier\cite{wallace}}
%
Wallace tree decomposes the multiplication all the way down to single bits.
%
Let us consider bit-vectors $x$ and $y$ that are accessed in the blocks of $1$
bit and are of size $k$.
%
In a Wallace tree, a partial product is the multiplication of single
bits $x_i*y_j$.
%
The multiplication of single bits is the conjunction of the bits, i.e.,
$x_i \land y_j$.
%
There is no carry generated due to the multiplication of single bits.
%
The partial product $x_i*y_j$ is aligned with the $(i+j-2)$th bit of output.
%
Let us consider the $o$th output bit.
%
All the partial products that are aligned to $o$ are summed using full adder 
and half adders.
%
The full adders are used
if more than two bits are available that are yet to be summed
and half adders are used if there are only two bits that are left to be summed.
%
The carry bits that are generated by the adders are aligned to the $(o+1)$th output bit.
%
The carry bits are summed to the partial products for $(o+1)th$ bit
using adders as illustrated in the following figure.

\begin{center}
  \begin{tikzpicture}[node distance=4cm,thick]

    \node[draw,rectangle, minimum width=2cm,minimum height=1cm] (a) {Adders};
    \node[draw,rectangle, minimum width=2cm,minimum height=1cm, right of=a] (b) {Adders};

    \draw[->] (a.south) -- node[right=1pt] {$o+1$} +(0,-.5);
    \draw[->] (b.south) -- node[right=1pt] {$o$} +(0,-.5);

    \draw[vecArrow] (b.220) |- ++(-1.5cm,-0.5) --node[right=1pt,yshift=-1cm,rotate = 90] {carry bits} ++(0,2.3cm) -| (a.40);

    \draw[vecArrow] ($ (a.140) + (0,0.6cm) $) --node[above=1pt,yshift = 1mm] {
      \begin{tabular}{c}
        partial\\
        products
      \end{tabular}
      } (a.140);
    \draw[vecArrow] ($ (b.140) + (0,0.6cm) $) --node[above=1pt,yshift = 1mm] {
      \begin{tabular}{c}
        partial\\
        products
      \end{tabular}
      } (b.140);

    \draw[vecArrow,gray] ($ (b.50) + (1cm,0.8cm) $) -| (b.50);
  \end{tikzpicture}  
\end{center}

Both the above multiplication methods do not
fully specify the design.
%
Therefore, there are several ways to implement the multiplications.
%
Therefore, it is not trivial to verify that a hardware design indeed
implements a multiplication.

% \ashu{Needs more detailed discussion with example about how
% verification problem may contain such multipliers expanded out!}

%--------------------- DO NOT ERASE BELOW THIS LINE --------------------------

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "main"
%%% End: 
